{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMRieq8Z3qYaG1yxk5qIXuA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Momina-Hussnain/Multimodal-ML-Housing-Price-Prediction-Using-Images-Tabular-Data/blob/main/Task_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, torchvision, sklearn, matplotlib, pandas\n",
        "print(\"Torch:\", torch.__version__)\n",
        "print(\"Torchvision:\", torchvision.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAFwVwNfPhRU",
        "outputId": "235fdba8-29b4-4529-bc4d-e63a03747b31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torch: 2.8.0+cu126\n",
            "Torchvision: 0.23.0+cu126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile Multimodal_Housing_Prediction.py\n",
        "import os\n",
        "import argparse\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Dataset\n",
        "# -----------------------------\n",
        "class HousingDataset(Dataset):\n",
        "    def __init__(self, csv_file, img_dir, transform=None, price_col=\"Price\", image_col=\"Image\"):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        # --- Detect target and image columns ---\n",
        "        if price_col not in self.data.columns:\n",
        "            raise ValueError(f\"CSV must contain target column (expected '{price_col}'). Found: {self.data.columns}\")\n",
        "        if image_col not in self.data.columns:\n",
        "            raise ValueError(f\"CSV must contain image column (expected '{image_col}'). Found: {self.data.columns}\")\n",
        "\n",
        "        # Targets\n",
        "        self.prices = self.data[price_col].values.astype(np.float32)\n",
        "\n",
        "        # Image file names\n",
        "        self.images = self.data[image_col].values\n",
        "\n",
        "        # Tabular = all numeric columns except target + image\n",
        "        drop_cols = [price_col, image_col]\n",
        "        self.tabular = self.data.drop(columns=drop_cols).values.astype(np.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Load image\n",
        "        img_path = os.path.join(self.img_dir, self.images[idx])\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        # Tabular and price\n",
        "        tab = torch.tensor(self.tabular[idx])\n",
        "        price = torch.tensor(self.prices[idx])\n",
        "\n",
        "        return image, tab, price\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Model\n",
        "# -----------------------------\n",
        "class MultimodalModel(nn.Module):\n",
        "    def __init__(self, tabular_dim):\n",
        "        super(MultimodalModel, self).__init__()\n",
        "        # Pretrained CNN (ResNet50 backbone)\n",
        "        cnn = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
        "        for param in cnn.parameters():\n",
        "            param.requires_grad = False\n",
        "        cnn.fc = nn.Identity()  # remove last layer\n",
        "        self.cnn = cnn\n",
        "\n",
        "        # Tabular branch\n",
        "        self.tabular_net = nn.Sequential(\n",
        "            nn.Linear(tabular_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        # Fusion + Regression\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(2048 + 64, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, image, tabular):\n",
        "        img_feat = self.cnn(image)           # [batch, 2048]\n",
        "        tab_feat = self.tabular_net(tabular) # [batch, 64]\n",
        "        fused = torch.cat((img_feat, tab_feat), dim=1)\n",
        "        out = self.fc(fused).squeeze(-1)     # [batch]\n",
        "        return out\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Training\n",
        "# -----------------------------\n",
        "def train_model(model, train_loader, val_loader, device, epochs=5, lr=1e-3):\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        for images, tab, prices in train_loader:\n",
        "            images, tab, prices = images.to(device), tab.to(device), prices.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images, tab)\n",
        "            loss = criterion(outputs, prices)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_losses.append(loss.item())\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        preds, targets = [], []\n",
        "        with torch.no_grad():\n",
        "            for images, tab, prices in val_loader:\n",
        "                images, tab, prices = images.to(device), tab.to(device), prices.to(device)\n",
        "                outputs = model(images, tab)\n",
        "                preds.extend(outputs.cpu().numpy())\n",
        "                targets.extend(prices.cpu().numpy())\n",
        "\n",
        "        mae = mean_absolute_error(targets, preds)\n",
        "        rmse = mean_squared_error(targets, preds) ** 0.5\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {np.mean(train_losses):.4f}, \"\n",
        "              f\"Val MAE: {mae:.2f}, Val RMSE: {rmse:.2f}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Main Pipeline\n",
        "# -----------------------------\n",
        "def run_pipeline(csv_file, img_dir, out_dir=\"outputs\", epochs=5, batch_size=16, lr=1e-3,\n",
        "                 price_col=\"Price\", image_col=\"Image\"):\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "    # Load CSV to detect tabular dimensions\n",
        "    df = pd.read_csv(csv_file)\n",
        "    tabular_dim = df.drop(columns=[price_col, image_col]).shape[1]\n",
        "\n",
        "    # Train-val split\n",
        "    train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "    train_csv, val_csv = os.path.join(out_dir, \"train.csv\"), os.path.join(out_dir, \"val.csv\")\n",
        "    train_df.to_csv(train_csv, index=False)\n",
        "    val_df.to_csv(val_csv, index=False)\n",
        "\n",
        "    # Image transforms\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "    # Datasets\n",
        "    train_dataset = HousingDataset(train_csv, img_dir, transform=transform,\n",
        "                                   price_col=price_col, image_col=image_col)\n",
        "    val_dataset = HousingDataset(val_csv, img_dir, transform=transform,\n",
        "                                 price_col=price_col, image_col=image_col)\n",
        "\n",
        "    # Dataloaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "    # Model\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"Device:\", device)\n",
        "    model = MultimodalModel(tabular_dim).to(device)\n",
        "\n",
        "    # Train\n",
        "    model = train_model(model, train_loader, val_loader, device, epochs=epochs, lr=lr)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--csv\", type=str, required=True, help=\"Path to CSV file\")\n",
        "    parser.add_argument(\"--imdir\", type=str, required=True, help=\"Path to image directory\")\n",
        "    parser.add_argument(\"--out\", type=str, default=\"outputs\", help=\"Output directory\")\n",
        "    parser.add_argument(\"--epochs\", type=int, default=5)\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=16)\n",
        "    parser.add_argument(\"--lr\", type=float, default=1e-3)\n",
        "    parser.add_argument(\"--price_col\", type=str, default=\"Price\", help=\"Target column name\")\n",
        "    parser.add_argument(\"--image_col\", type=str, default=\"Image\", help=\"Image filename column name\")\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    run_pipeline(args.csv, args.imdir, out_dir=args.out,\n",
        "                 epochs=args.epochs, batch_size=args.batch_size, lr=args.lr,\n",
        "                 price_col=args.price_col, image_col=args.image_col)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4ykISeaXl7D",
        "outputId": "4aea1b32-7e6e-4a2e-be3e-3f9a675ab0a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting Multimodal_Housing_Prediction.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"./synthetic_demo/data.csv\")\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k20RvN-cXtxw",
        "outputId": "39c29a95-fa0c-44e6-9904-fef6c4d1138e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id       image_path  sqft  bedrooms  bathrooms  year_built          price\n",
            "0   0  image_00000.jpg  1698         3          1        1973  114752.070965\n",
            "1   1  image_00001.jpg  1604         2          1        1962   76264.513476\n",
            "2   2  image_00002.jpg  1369         2          1        1993   78141.671961\n",
            "3   3  image_00003.jpg  1398         5          4        1978  144442.799065\n",
            "4   4  image_00004.jpg   968         1          1        2009   50000.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python Multimodal_Housing_Prediction.py \\\n",
        "    --csv ./synthetic_demo/data.csv \\\n",
        "    --imdir ./synthetic_demo/images \\\n",
        "    --out ./outputs \\\n",
        "    --epochs 5 \\\n",
        "    --batch_size 16 \\\n",
        "    --lr 0.001 \\\n",
        "    --price_col price \\\n",
        "    --image_col image_path\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPFHT1fjYL7o",
        "outputId": "9c69edec-c94e-4327-daec-223db211018d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n",
            "100% 97.8M/97.8M [00:00<00:00, 190MB/s]\n",
            "Epoch 1/5, Train Loss: 15843188462.9333, Val MAE: 107784.95, Val RMSE: 117044.35\n",
            "Epoch 2/5, Train Loss: 10906355865.6000, Val MAE: 52891.15, Val RMSE: 65697.14\n",
            "Epoch 3/5, Train Loss: 2525832576.0000, Val MAE: 36118.62, Val RMSE: 44167.53\n",
            "Epoch 4/5, Train Loss: 1952037196.8000, Val MAE: 34971.51, Val RMSE: 42878.25\n",
            "Epoch 5/5, Train Loss: 1961802338.1333, Val MAE: 35375.32, Val RMSE: 43328.35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load full dataset\n",
        "df = pd.read_csv(\"./synthetic_demo/data.csv\")\n",
        "\n",
        "# Split into train and validation\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Save splits\n",
        "train_df.to_csv(\"./synthetic_demo/train.csv\", index=False)\n",
        "val_df.to_csv(\"./synthetic_demo/val.csv\", index=False)\n",
        "\n",
        "print(\"Train size:\", len(train_df))\n",
        "print(\"Val size:\", len(val_df))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qA_snYR8YSSn",
        "outputId": "1a427f65-5b7d-4043-cb24-901635284ed1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 480\n",
            "Val size: 120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python Multimodal_Housing_Prediction.py \\\n",
        "    --csv ./synthetic_demo/train.csv \\\n",
        "    --imdir ./synthetic_demo/images \\\n",
        "    --out ./outputs \\\n",
        "    --epochs 5 \\\n",
        "    --batch_size 16 \\\n",
        "    --lr 0.001 \\\n",
        "    --price_col price \\\n",
        "    --image_col image_path\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtdfnvaIYYP1",
        "outputId": "73d94586-7f46-4312-91e1-c2e641a5a0ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "Epoch 1/5, Train Loss: 15812474837.3333, Val MAE: 119523.66, Val RMSE: 128829.60\n",
            "Epoch 2/5, Train Loss: 14129655893.3333, Val MAE: 102587.98, Val RMSE: 113119.13\n",
            "Epoch 3/5, Train Loss: 7520639893.3333, Val MAE: 44456.59, Val RMSE: 58310.49\n",
            "Epoch 4/5, Train Loss: 2108135464.0000, Val MAE: 35485.33, Val RMSE: 46769.50\n",
            "Epoch 5/5, Train Loss: 1923024296.0000, Val MAE: 34575.50, Val RMSE: 47113.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python Multimodal_Housing_Prediction.py \\\n",
        "    --csv ./synthetic_demo/train.csv \\\n",
        "    --imdir ./synthetic_demo/images \\\n",
        "    --out ./outputs \\\n",
        "    --epochs 5 \\\n",
        "    --batch_size 16 \\\n",
        "    --lr 0.001 \\\n",
        "    --price_col price \\\n",
        "    --image_col image_path\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quTIERwMYmjY",
        "outputId": "6333eea5-58d7-4da0-c0a4-1537c5f0f675"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "Epoch 1/5, Train Loss: 15843209813.3333, Val MAE: 119734.22, Val RMSE: 129030.60\n",
            "Epoch 2/5, Train Loss: 14135594752.0000, Val MAE: 102040.63, Val RMSE: 112650.04\n",
            "Epoch 3/5, Train Loss: 7239960842.6667, Val MAE: 42623.34, Val RMSE: 55893.12\n",
            "Epoch 4/5, Train Loss: 2169777712.0000, Val MAE: 34732.40, Val RMSE: 46437.04\n",
            "Epoch 5/5, Train Loss: 1895639626.6667, Val MAE: 34533.73, Val RMSE: 47092.90\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python Multimodal_Housing_Prediction.py \\\n",
        "    --csv ./synthetic_demo/data.csv \\\n",
        "    --imdir ./synthetic_demo/images \\\n",
        "    --out ./outputs \\\n",
        "    --epochs 5 \\\n",
        "    --batch_size 16 \\\n",
        "    --lr 0.001 \\\n",
        "    --price_col price \\\n",
        "    --image_col image_path\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRZcBXmCY5_O",
        "outputId": "c453faa9-202f-4c63-bb5e-e85283dd96fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "Epoch 1/5, Train Loss: 15997082043.7333, Val MAE: 110553.66, Val RMSE: 119648.88\n",
            "Epoch 2/5, Train Loss: 12925920256.0000, Val MAE: 75635.26, Val RMSE: 87916.30\n",
            "Epoch 3/5, Train Loss: 4106953587.2000, Val MAE: 37960.64, Val RMSE: 46607.47\n",
            "Epoch 4/5, Train Loss: 1997263863.4667, Val MAE: 35377.29, Val RMSE: 43198.66\n",
            "Epoch 5/5, Train Loss: 1971524467.2000, Val MAE: 35268.11, Val RMSE: 43105.51\n"
          ]
        }
      ]
    }
  ]
}